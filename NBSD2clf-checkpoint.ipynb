{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "### Using Naive Bayes to predict spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Latin encoding as the Data has non UFT-8 Chars\n",
    "df = pd.read_csv(\"spam.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.v2,\n",
    "    df.v1, \n",
    "    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class sklearn.feature_extraction.text.TfidfVectorizer(input=’content’, encoding=’utf-8’, decode_error=’strict’, strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer=’word’, stop_words=None, token_pattern=’(?u)\\b\\w\\w+\\b’, ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class ‘numpy.int64’>, norm=’l2’, use_idf=True, smooth_idf=True, sublinear_tf=False)[source]¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a collection of raw documents to a matrix of vectors( array of numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\t\n",
    "input : string {‘filename’, ‘file’, ‘content’}\n",
    "\n",
    "\n",
    "encoding : string, ‘utf-8’ by default.\n",
    "\n",
    "If bytes or files are given to analyze, this encoding is used to decode.\n",
    "\n",
    "decode_error : {‘strict’, ‘ignore’, ‘replace’}\n",
    "\n",
    "Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given encoding. By default, it is ‘strict’, meaning that a UnicodeDecodeError will be raised. Other values are ‘ignore’ and ‘replace’.\n",
    "\n",
    "\n",
    "\n",
    "analyzer : string, {‘word’, ‘char’} or callable\n",
    "\n",
    "Whether the feature should be made of word or character.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The lower and upper boundary of the range of n-values \n",
    "\n",
    "stop_words : string {‘english’}, list, or None (default)\n",
    "\n",
    "If a string, it is passed to _check_stop_list and the appropriate stop list is returned. ‘english’ is currently the only supported string value.\n",
    "\n",
    "If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens. Only applies if analyzer == 'word'.\n",
    "\n",
    "\n",
    "vocabulary : Mapping or iterable, optional\n",
    "\n",
    "\n",
    "binary : boolean, default=False\n",
    "\n",
    "If True, all non-zero term counts are set to 1.\n",
    "\n",
    "dtype : type, optional\n",
    "\n",
    "Type of the matrix returned by fit_transform() or transform().\n",
    "\n",
    "norm : ‘l1’, ‘l2’ or None, optional\n",
    "\n",
    "Norm used to normalize term vectors. None for no normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed  = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5545        Hi its in durban are you still on this number\n",
      "3030     gonna let me know cos comes bak from holiday ...\n",
      "2019               From tomorrow onwards eve 6 to 3 work.\n",
      "1359    &lt;#&gt; %of pple marry with their lovers... ...\n",
      "Name: v2, dtype: object\n",
      "  (0, 3185)\t0.336597371425752\n",
      "  (0, 3495)\t0.2957964364724077\n",
      "  (0, 3378)\t0.20548758607023213\n",
      "  (0, 2338)\t0.5684228244690185\n",
      "  (0, 964)\t0.24486244909281268\n",
      "  (0, 7149)\t0.15808709625025885\n",
      "  (0, 6024)\t0.31236525813553684\n",
      "  (0, 4590)\t0.2401512147338128\n",
      "  (0, 6356)\t0.26774149253266777\n",
      "  (0, 4519)\t0.3492817001859606\n",
      "  (1, 4519)\t0.23194352771782634\n",
      "  (1, 2964)\t0.2626650028207571\n",
      "  (1, 3802)\t0.24308505875319902\n",
      "  (1, 4107)\t0.24309778315100802\n",
      "  (1, 3682)\t0.18729460101653797\n",
      "  (1, 1899)\t0.2398416674123413\n",
      "  (1, 1790)\t0.29468795421793115\n",
      "  (1, 1118)\t0.3383214696453111\n",
      "  (1, 2816)\t0.18414066490778583\n",
      "  (1, 3224)\t0.27108814081455723\n",
      "  (1, 6320)\t0.15811957008213634\n",
      "  (1, 2043)\t0.19462597416640542\n",
      "  (1, 3477)\t0.13965516743967052\n",
      "  (1, 1793)\t0.2666848721565729\n",
      "  (1, 2259)\t0.21735132575617205\n",
      "  :\t:\n",
      "  (3, 2194)\t0.1387000818499756\n",
      "  (3, 6973)\t0.15640161318972634\n",
      "  (3, 2905)\t0.08351515803531348\n",
      "  (3, 4433)\t0.15051131463539957\n",
      "  (3, 2800)\t0.15230834079005048\n",
      "  (3, 1475)\t0.10196275117924936\n",
      "  (3, 4800)\t0.13100068355014877\n",
      "  (3, 3829)\t0.09530624047535222\n",
      "  (3, 884)\t0.06619001844598374\n",
      "  (3, 6976)\t0.14038194162611856\n",
      "  (3, 1176)\t0.08542896386363277\n",
      "  (3, 6324)\t0.06073250548860957\n",
      "  (3, 1229)\t0.13173684266984786\n",
      "  (3, 7154)\t0.0725413025982359\n",
      "  (3, 3817)\t0.12214036478174466\n",
      "  (3, 2262)\t0.10493227839622214\n",
      "  (3, 1383)\t0.25483780801729766\n",
      "  (3, 1604)\t0.18343181596205743\n",
      "  (3, 3347)\t0.08386733532179129\n",
      "  (3, 6109)\t0.19253484889593245\n",
      "  (3, 5585)\t0.09864430340064924\n",
      "  (3, 2810)\t0.14884752828809678\n",
      "  (3, 4193)\t0.1289268247678545\n",
      "  (3, 6954)\t0.19253484889593245\n",
      "  (3, 5202)\t0.15230834079005048\n"
     ]
    }
   ],
   "source": [
    "print (X_train[1:5])\n",
    "print (X_train_transformed[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train_transformed = selector.transform(X_train_transformed).toarray()\n",
    "data_test_transformed  = selector.transform(X_test_transformed).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print (data_train_transformed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8301435406698564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1376,   81],\n",
       "       [ 203,   12]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "clf = GaussianNB()\n",
    "clf.fit(data_train_transformed, labels_train)\n",
    "predictions = clf.predict(data_test_transformed)\n",
    "\n",
    "print(accuracy_score(labels_test, predictions))\n",
    "confusion_matrix(labels_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAUSSIAN VS BERNOULLI VS MULTINOMIAL\n",
    "\n",
    "Multi-variate Bernoulli Naive Bayes The binomial model is useful if your feature vectors are binary (i.e., 0s and 1s). One application would be text classification with a bag of words model where the 0s 1s are \"word occurs in the document\" and \"word does not occur in the document\"\n",
    "\n",
    "Multinomial Naive Bayes The multinomial naive Bayes model is typically used for discrete counts. E.g., if we have a text classification problem, we can take the idea of bernoulli trials one step further and instead of \"word occurs in the document\" we have \"count how often word occurs in the document\", you can think of it as \"number of times outcome number x_i is observed over the n trials\"\n",
    "\n",
    "Gaussian Naive Bayes Here, we assume that the features follow a normal distribution. Instead of discrete counts, we have continuous features (e.g., the popular Iris dataset where the features are sepal width, petal width, sepal length, petal length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Hi Ashok, We have a meeting this afternoon.\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewEmail = pd.Series([\"Hi Ashok, We have a meeting this afternoon.\"])\n",
    "NewEmail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype='<U4')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewEmail_transformed = vectorizer.transform(NewEmail)\n",
    "NewEmail_transformed  = selector.transform(NewEmail_transformed).toarray()\n",
    "clf.predict(NewEmail_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.87      0.94      0.91      1457\n",
      "       spam       0.13      0.06      0.08       215\n",
      "\n",
      "avg / total       0.78      0.83      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
